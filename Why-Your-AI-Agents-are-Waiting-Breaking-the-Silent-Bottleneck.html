<!DOCTYPE html>
<html lang="zh">
<head>
  <meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1">
  <title>Why Your AI Agents are Waiting: Breaking the Silent Bottleneck in LLM Inference · 深渊研究室</title>
  <link href="https://fonts.googleapis.com/css2?family=Lora:ital,wght@0,400;0,600;1,400&family=JetBrains+Mono:wght@400;500&family=Source+Sans+3:wght@300;400;600&display=swap" rel="stylesheet">
  <style>
    :root{--bg:#faf8f4;--surface:#f2ede5;--border:#ddd8cc;--text:#1a1814;--muted:#7a7268;--accent:#c0392b;--accent-light:#f5e6e4;--link:#2c5282;--code-bg:#ece8e0}
    [data-theme="dark"]{--bg:#141210;--surface:#1e1c18;--border:#2e2b24;--text:#e8e4dc;--muted:#8a8278;--accent:#e05a4e;--accent-light:#2a1a18;--link:#7eb8e8;--code-bg:#1a1814}
    *,*::before,*::after{box-sizing:border-box;margin:0;padding:0}
    body{font-family:'Source Sans 3',sans-serif;background:var(--bg);color:var(--text);font-size:17px;line-height:1.7;transition:background .3s,color .3s}
    .topbar{position:sticky;top:0;z-index:100;background:var(--bg);border-bottom:1px solid var(--border);padding:.9rem 2rem;display:flex;justify-content:space-between;align-items:center;backdrop-filter:blur(8px)}
    .back-link{font-family:'JetBrains Mono',monospace;font-size:.8rem;color:var(--muted);text-decoration:none}.back-link:hover{color:var(--accent)}
    .theme-btn{background:none;border:1px solid var(--border);border-radius:6px;padding:.25rem .55rem;font-size:.75rem;color:var(--muted);cursor:pointer;font-family:'JetBrains Mono',monospace}.theme-btn:hover{border-color:var(--accent);color:var(--accent)}
    .progress-bar{position:fixed;top:0;left:0;height:2px;background:var(--accent);z-index:200;transition:width .1s}
    .page{max-width:1100px;margin:0 auto;display:grid;grid-template-columns:1fr 220px;gap:4rem;padding:4rem 2rem 8rem}
    .post-meta{margin-bottom:2rem}
    .post-date{font-family:'JetBrains Mono',monospace;font-size:.8rem;color:var(--muted);margin-bottom:.8rem}
    .post-title{font-family:'Lora',serif;font-size:2.2rem;font-weight:600;line-height:1.3;margin-bottom:1rem}
    .post-tags{display:flex;flex-wrap:wrap;gap:.4rem;margin-bottom:1.5rem}
    .tag{font-size:.72rem;padding:.2rem .55rem;border-radius:100px;background:var(--surface);color:var(--muted);font-family:'JetBrains Mono',monospace}.tag.hl{background:var(--accent-light);color:var(--accent)}
    .post-desc{font-size:1.05rem;color:var(--muted);line-height:1.7;padding:1.2rem 1.5rem;border-left:3px solid var(--accent);background:var(--surface);border-radius:0 8px 8px 0}
    .divider{height:1px;background:var(--border);margin:2.5rem 0}
    .prose{max-width:680px}
    .prose h2{font-family:'Lora',serif;font-size:1.5rem;font-weight:600;margin:2.5rem 0 1rem}
    .prose h3{font-family:'Lora',serif;font-size:1.15rem;font-weight:600;margin:2rem 0 .7rem}
    .prose p{margin-bottom:1.2rem}.prose a{color:var(--link);text-decoration:underline;text-underline-offset:3px}.prose a:hover{color:var(--accent)}
    .prose strong{font-weight:600}.prose em{font-style:italic;font-family:'Lora',serif}
    .prose ul,.prose ol{padding-left:1.5rem;margin-bottom:1.2rem}.prose li{margin-bottom:.4rem}
    .prose pre{background:var(--code-bg);border:1px solid var(--border);border-radius:8px;padding:1.2rem 1.4rem;overflow-x:auto;margin:1.5rem 0;font-size:.82rem;line-height:1.65;white-space:pre-wrap}
    .prose code{font-family:'JetBrains Mono',monospace;font-size:.85em}
    .prose p code,.prose li code{background:var(--code-bg);padding:.1em .4em;border-radius:4px;font-size:.83em}
    .prose blockquote{border-left:3px solid var(--accent);padding:.8rem 1.2rem;margin:1.5rem 0;background:var(--surface);border-radius:0 6px 6px 0;color:var(--muted);font-style:italic;font-family:'Lora',serif}
    .prose table{width:100%;border-collapse:collapse;font-size:.88rem;margin:1.5rem 0}
    .prose th{background:var(--surface);font-family:'JetBrains Mono',monospace;font-size:.75rem;padding:.6rem 1rem;text-align:left;border-bottom:2px solid var(--border);color:var(--muted)}
    .prose td{padding:.6rem 1rem;border-bottom:1px solid var(--border)}
    .toc-sidebar{position:sticky;top:5rem;height:fit-content}
    .toc-title{font-family:'JetBrains Mono',monospace;font-size:.72rem;color:var(--muted);text-transform:uppercase;letter-spacing:.1em;margin-bottom:.8rem}
    .toc-list{list-style:none;display:flex;flex-direction:column}
    .toc-item a{display:block;font-size:.82rem;color:var(--muted);text-decoration:none;padding:.3rem .7rem;border-left:2px solid var(--border);transition:all .15s;line-height:1.4}
    .toc-item a:hover,.toc-item.active a{color:var(--accent);border-left-color:var(--accent)}
    .toc-item.sub a{padding-left:1.4rem;font-size:.78rem}
    @media(max-width:900px){.page{grid-template-columns:1fr}.toc-sidebar{display:none}.post-title{font-size:1.7rem}}
    @keyframes fadeIn{from{opacity:0;transform:translateY(10px)}to{opacity:1;transform:translateY(0)}}
    article{animation:fadeIn .5s ease}
  </style>
</head>
<body>
<div class="progress-bar" id="progress"></div>
<nav class="topbar">
  <a href="index.html" class="back-link">← 所有文章</a>
  <button class="theme-btn" onclick="toggleTheme()">◑ theme</button>
</nav>
<div class="page">
  <article>
    <div class="post-meta">
      <div class="post-date">2026-02-27 · 预计阅读 13 分钟</div>
      <h1 class="post-title">Why Your AI Agents are Waiting: Breaking the Silent Bottleneck in LLM Inference</h1>
      
      <div class="post-desc">https://arxiv.org/pdf/2602.21548</div>
    </div>
    <div class="divider"></div>
    <div class="prose" id="prose">
<p>https://arxiv.org/pdf/2602.21548</p>
<p><strong>Motivation</strong> Multi-turn agentic LLM inference in layer-wise prefill 、PD disaggregated、KV Cache Storage architecture, KV-Cache storage I/O imbalance. Storage NICs on prefill engines became bandwidth-saturated, while those on decoding engines remain idle. This asymmetry constrains overall system throughput. The idea is how to use decoding engines bandwidth. We call dual-path KV-Cache loading. The challenge is how to load across prefill and decoding engines to achieve dynamically balances.</p>
<p><strong>Challenges</strong> 1、introducing an extra loading path introduces complex traffic patterns 2、online decision under dynamic and heterogeneous workloads, and ensure load balance across both GPU’s and NICs</p>
<p><strong>Innovations</strong> 1、  identify the I/O-bound nature of multi-turn, agentic LLM workloads and show that KV-Cache loading dominates system performance under modern LLM inference architectures. 2、  Present Dual-Path, introduce dual-path kv-cache loading and leverage all engine to resolve prefill-side bottlenecks. 3、  Design and evaluate a workload-aware scheduling algorithm that dynamically balance computation and network resources.</p>
<p><strong>Existed Solutions</strong> 1、  MoonCake: caches KV-Cache in a distributed DRAM pool and employs an affinity-aware scheduler to maximize the DRAM KV-Cache hit rate， but is can’t used in memory-constrained scenerios, such as the rollout phrase in RL, where DRAM is occupied to hold large training state that is offloaded from HBM. It is also not cost-effective in scenarios with enormous working sets (e.g., online serving), considering the cost comparison between DRAM and SSD https://arxiv.org/pdf/2407.00079 2、reduce the amount of KVCache data to retrieve and reduce the retrieval overhead，do not solve the inherent inefficiency caused by storage I/O imbalance between different engines https://arxiv.org/pdf/2410.05004 <strong>Takeaway 1 Transforming local bandwidth into“Global Pooled Resources”</strong> Key Technical Points: DE Buffer and HBM Efficiency DualPath introduces a dedicated DE Buffer on the DE side. This is not only for data transfer, but also a clever choice regarding HBM (video memory) utilization: by buffering data in DRAM, it significantly reduces the time to first word generation (TTFT) phase on precious GPU HBM, thereby supporting larger-scale concurrency.</p>
<p><strong>Takeaway 2: Fine-grained Management: CNIC-Driven "Traffic Isolation"</strong> QoS Isolation: Utilizing Virtual Channel (VL) technology, inference computation communications are given the highest priority (99% bandwidth reserved), while KV-Cache transfers are placed in a low-priority position. RDMA Replaces CUDA Copy: Traditional cudaMemcpyAsync incurs a 5-7μs system overhead, while DualPath reduces this overhead to ~1μs by driving the CNIC for RDMA transfers. <strong> </strong> <strong>Takeaway 3: Intelligent Scheduling: Global Load Balancing Centered on "Token Count"</strong> DualPath monitors two dimensions of the cluster in real time: NIC traffic load and GPU utilization. The scheduler uses Token Count as a proxy metric for global load balancing. By dynamically allocating task quotas for PE and DE, the system ensures that no single node's network interface card becomes a bottleneck for overall performance. <strong>Conclusion: Beyond the Compute-First Mindset</strong> The era of solving performance problems by simply buying faster chips is over. The "Silent Bottleneck" of I/O has become the primary constraint for the next generation of agentic AI. As contexts grow from thousands to millions of tokens, we must move away from the traditional silos of "storage vs. compute." Every node in the data center must become an active, load-balanced participant in the memory hierarchy. The question for every systems architect is now: Is your infrastructure designed to think, or is it just designed to wait?</p>
    </div>
    <div class="divider"></div>
    <div style="font-size:.85rem;color:var(--muted);font-family:'JetBrains Mono',monospace;display:flex;justify-content:space-between;flex-wrap:wrap;gap:1rem">
      <span>// 如有错误请通过 GitHub Issues 指正</span>
      <a href="index.html" style="color:var(--accent);text-decoration:none">← 返回文章列表</a>
    </div>
  </article>
  <aside class="toc-sidebar"></aside>
</div>
<script>
  function toggleTheme(){const c=document.documentElement.getAttribute('data-theme');document.documentElement.setAttribute('data-theme',c==='dark'?'light':'dark');localStorage.setItem('theme',c==='dark'?'light':'dark')}
  const saved=localStorage.getItem('theme');if(saved)document.documentElement.setAttribute('data-theme',saved);
  window.addEventListener('scroll',()=>{
    const d=document.documentElement,s=d.scrollTop,t=d.scrollHeight-d.clientHeight;
    document.getElementById('progress').style.width=(s/t*100)+'%';
    const hs=document.querySelectorAll('.prose h2,.prose h3'),ti=document.querySelectorAll('.toc-item');
    let cur='';hs.forEach(h=>{if(h.offsetTop-100<=s)cur=h.id});
    ti.forEach(i=>{const a=i.querySelector('a');i.classList.toggle('active',a&&a.getAttribute('href')==='#'+cur)});
  });
</script>
</body>
</html>
